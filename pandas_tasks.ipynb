{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/islavathnaveennaik/panda_task/blob/main/pandas_tasks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8Rt5j-jj5JQ"
      },
      "source": [
        "# pandas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COAftRnOj5JT"
      },
      "source": [
        "## Importing pandas\n",
        "\n",
        "### Getting started and checking your pandas setup\n",
        "\n",
        "Difficulty: *easy*\n",
        "\n",
        "**1.** Import pandas under the name `pd`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "_dProofBj5JU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVHCKFk2j5JV"
      },
      "source": [
        "**2.** Print the version of pandas that has been imported."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "f2a4eEVsj5JV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "293b8397-ca0a-42d4-ffe6-c8a51619f29f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2.2\n"
          ]
        }
      ],
      "source": [
        "print(pd.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvpLBEX4j5JV"
      },
      "source": [
        "**3.** Print out all the version information of the libraries that are required by the pandas library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "uVLpbnlkj5JW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a28372a6-2689-4ddf-ff33-21feed8c0986"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: pandas\n",
            "Version: 2.2.2\n",
            "Summary: Powerful data structures for data analysis, time series, and statistics\n",
            "Home-page: https://pandas.pydata.org\n",
            "Author: \n",
            "Author-email: The Pandas Development Team <pandas-dev@python.org>\n",
            "License: BSD 3-Clause License\n",
            "\n",
            "Copyright (c) 2008-2011, AQR Capital Management, LLC, Lambda Foundry, Inc. and PyData Development Team\n",
            "All rights reserved.\n",
            "\n",
            "Copyright (c) 2011-2023, Open source contributors.\n",
            "\n",
            "Redistribution and use in source and binary forms, with or without\n",
            "modification, are permitted provided that the following conditions are met:\n",
            "\n",
            "* Redistributions of source code must retain the above copyright notice, this\n",
            "  list of conditions and the following disclaimer.\n",
            "\n",
            "* Redistributions in binary form must reproduce the above copyright notice,\n",
            "  this list of conditions and the following disclaimer in the documentation\n",
            "  and/or other materials provided with the distribution.\n",
            "\n",
            "* Neither the name of the copyright holder nor the names of its\n",
            "  contributors may be used to endorse or promote products derived from\n",
            "  this software without specific prior written permission.\n",
            "\n",
            "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
            "AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
            "IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
            "DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
            "FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
            "DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
            "SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
            "CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
            "OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
            "OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: numpy, python-dateutil, pytz, tzdata\n",
            "Required-by: arviz, bigframes, bigquery-magics, bokeh, bqplot, cmdstanpy, cudf-cu12, cufflinks, dask-cuda, dask-cudf-cu12, dask-expr, datascience, db-dtypes, dopamine_rl, fastai, geemap, geopandas, google-colab, gspread-dataframe, holoviews, ibis-framework, mizani, mlxtend, pandas-datareader, pandas-gbq, panel, plotnine, prophet, pymc, seaborn, shap, sklearn-pandas, statsmodels, vega-datasets, xarray, yfinance\n"
          ]
        }
      ],
      "source": [
        "pip show pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgHYCAw1j5JW"
      },
      "source": [
        "## DataFrame basics\n",
        "\n",
        "### A few of the fundamental routines for selecting, sorting, adding and aggregating data in DataFrames\n",
        "\n",
        "Difficulty: *easy*\n",
        "\n",
        "Note: remember to import numpy using:\n",
        "```python\n",
        "import numpy as np\n",
        "```\n",
        "\n",
        "Consider the following Python dictionary `data` and Python list `labels`:\n",
        "\n",
        "``` python\n",
        "data = {'animal': ['cat', 'cat', 'snake', 'dog', 'dog', 'cat', 'snake', 'cat', 'dog', 'dog'],\n",
        "        'age': [2.5, 3, 0.5, np.nan, 5, 2, 4.5, np.nan, 7, 3],\n",
        "        'visits': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
        "        'priority': ['yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no']}\n",
        "\n",
        "labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
        "```\n",
        "(This is just some meaningless data I made up with the theme of animals and trips to a vet.)\n",
        "\n",
        "**4.** Create a DataFrame `df` from this dictionary `data` which has the index `labels`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "5oiGhjb1j5JX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf29270e-610e-4995-d713-902f339cb977"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  animal  age  visits priority\n",
            "a    cat  2.5       1      yes\n",
            "b    cat  3.0       3      yes\n",
            "c  snake  0.5       2       no\n",
            "d    dog  NaN       3      yes\n",
            "e    dog  5.0       2       no\n",
            "f    cat  2.0       3       no\n",
            "g  snake  4.5       1       no\n",
            "h    cat  NaN       1      yes\n",
            "i    dog  7.0       2       no\n",
            "j    dog  3.0       1       no\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = {'animal': ['cat', 'cat', 'snake', 'dog', 'dog', 'cat', 'snake', 'cat', 'dog', 'dog'],\n",
        "        'age': [2.5, 3, 0.5, np.nan, 5, 2, 4.5, np.nan, 7, 3],\n",
        "        'visits': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
        "        'priority': ['yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no']}\n",
        "\n",
        "labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
        "\n",
        "df = pd.DataFrame(data, index=labels)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtdsB-7hj5JX"
      },
      "source": [
        "**5.** Display a summary of the basic information about this DataFrame and its data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "id": "2MGnmlqMj5JY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a3f5947-8d57-46f2-e847-8cbdc010947d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 10 entries, a to j\n",
            "Data columns (total 4 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   animal    10 non-null     object \n",
            " 1   age       8 non-null      float64\n",
            " 2   visits    10 non-null     int64  \n",
            " 3   priority  10 non-null     object \n",
            "dtypes: float64(1), int64(1), object(2)\n",
            "memory usage: 400.0+ bytes\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UP9RfEHSj5JY"
      },
      "source": [
        "**6.** Return the first 3 rows of the DataFrame `df`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "id": "nx7Ny05lj5JY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7ada5a8-87b7-4719-d9b1-c62836f473bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  animal  age  visits priority\n",
            "a    cat  2.5       1      yes\n",
            "b    cat  3.0       3      yes\n",
            "c  snake  0.5       2       no\n"
          ]
        }
      ],
      "source": [
        "print(df.head(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeuXsE-jj5JY"
      },
      "source": [
        "**7.** Select just the 'animal' and 'age' columns from the DataFrame `df`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "mQTmRQrkj5JY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8735af4b-d7b8-48b2-bb96-70da33d752c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  animal  age\n",
            "a    cat  2.5\n",
            "b    cat  3.0\n",
            "c  snake  0.5\n",
            "d    dog  NaN\n",
            "e    dog  5.0\n",
            "f    cat  2.0\n",
            "g  snake  4.5\n",
            "h    cat  NaN\n",
            "i    dog  7.0\n",
            "j    dog  3.0\n"
          ]
        }
      ],
      "source": [
        "selected_df = df[['animal', 'age']]\n",
        "print(selected_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSliTSD0j5JY"
      },
      "source": [
        "**8.** Select the data in rows `[3, 4, 8]` *and* in columns `['animal', 'age']`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "zaE0eCjQj5JZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a01aa0f0-e083-47a5-bfdf-1c9b93db1210"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  animal  age\n",
            "d    dog  NaN\n",
            "e    dog  5.0\n",
            "i    dog  7.0\n"
          ]
        }
      ],
      "source": [
        "selected_df = df.loc[['d', 'e', 'i'], ['animal', 'age']]\n",
        "print(selected_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nCnYULmj5JZ"
      },
      "source": [
        "**9.** Select only the rows where the number of visits is greater than 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "id": "Rs6QpQVNj5JZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16cd7987-76ef-43a7-fcd4-fa57584ce6b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [animal, age, visits, priority]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "selected_df = df[df['visits'] > 3]\n",
        "print(selected_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmCSW80qj5JZ"
      },
      "source": [
        "**10.** Select the rows where the age is missing, i.e. is `NaN`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "id": "9Tab4jGVj5Ja",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eae72c6-cdc3-47f8-9cc6-2716ec60625c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  animal  age  visits priority\n",
            "d    dog  NaN       3      yes\n",
            "h    cat  NaN       1      yes\n"
          ]
        }
      ],
      "source": [
        "missing_age_df = df[df['age'].isna()]\n",
        "print(missing_age_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVZkPiMYj5Ja"
      },
      "source": [
        "**11.** Select the rows where the animal is a cat *and* the age is less than 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "id": "dlkwwWCWj5Ja",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a44d56c-9da4-44c1-ec59-e14c5bfb5cb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  animal  age  visits priority\n",
            "a    cat  2.5       1      yes\n",
            "f    cat  2.0       3       no\n"
          ]
        }
      ],
      "source": [
        "selected_df = df[(df['animal'] == 'cat') & (df['age'] < 3)]\n",
        "print(selected_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUaJhWKoj5Ja"
      },
      "source": [
        "**12.** Select the rows the age is between 2 and 4 (inclusive)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "id": "OPVCSObDj5Jb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fdf02e0-a30e-4595-be9b-915527efb715"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  animal  age  visits priority\n",
            "a    cat  2.5       1      yes\n",
            "b    cat  3.0       3      yes\n",
            "f    cat  2.0       3       no\n",
            "j    dog  3.0       1       no\n"
          ]
        }
      ],
      "source": [
        "selected_df = df[(df['age'] >= 2) & (df['age'] <= 4)]\n",
        "print(selected_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-R4-2z3j5Jb"
      },
      "source": [
        "**13.** Change the age in row 'f' to 1.5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "id": "XHUgpZkuj5Jb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c44fe948-392b-4c6c-cfbd-4ee5198b1374"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  animal  age  visits priority\n",
            "a    cat  2.5       1      yes\n",
            "b    cat  3.0       3      yes\n",
            "c  snake  0.5       2       no\n",
            "d    dog  NaN       3      yes\n",
            "e    dog  5.0       2       no\n",
            "f    cat  1.5       3       no\n",
            "g  snake  4.5       1       no\n",
            "h    cat  NaN       1      yes\n",
            "i    dog  7.0       2       no\n",
            "j    dog  3.0       1       no\n"
          ]
        }
      ],
      "source": [
        "df.loc['f', 'age'] = 1.5\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6qba8cFj5Jb"
      },
      "source": [
        "**14.** Calculate the sum of all visits (the total number of visits)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "id": "5qqjWfsvj5Jc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5146c67a-19b3-4176-a2dc-558b9e895b20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19\n"
          ]
        }
      ],
      "source": [
        "total_visits = df['visits'].sum()\n",
        "print(total_visits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNcRK9QVj5Jc"
      },
      "source": [
        "**15.** Calculate the mean age for each different animal in `df`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "id": "Zszsv0S4j5Jc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09cb7ab4-779e-43a7-9be1-0ec911053f47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "animal\n",
            "cat      2.333333\n",
            "dog      5.000000\n",
            "snake    2.500000\n",
            "Name: age, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "mean_age_by_animal = df.groupby('animal')['age'].mean()\n",
        "print(mean_age_by_animal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwWd6Barj5Jc"
      },
      "source": [
        "**16.** Append a new row 'k' to `df` with your choice of values for each column. Then delete that row to return the original DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "collapsed": true,
        "id": "ks2oxcvGj5Jd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "091b3310-9390-4bdd-f515-60dfa9a22f3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  animal  age  visits priority\n",
            "a    cat  2.5       1      yes\n",
            "b    cat  3.0       3      yes\n",
            "c  snake  0.5       2       no\n",
            "d    dog  NaN       3      yes\n",
            "e    dog  5.0       2       no\n",
            "f    cat  1.5       3       no\n",
            "g  snake  4.5       1       no\n",
            "h    cat  NaN       1      yes\n",
            "i    dog  7.0       2       no\n",
            "j    dog  3.0       1       no\n",
            "k    dog  2.5       2       no\n",
            "  animal  age  visits priority\n",
            "a    cat  2.5       1      yes\n",
            "b    cat  3.0       3      yes\n",
            "c  snake  0.5       2       no\n",
            "d    dog  NaN       3      yes\n",
            "e    dog  5.0       2       no\n",
            "f    cat  1.5       3       no\n",
            "g  snake  4.5       1       no\n",
            "h    cat  NaN       1      yes\n",
            "i    dog  7.0       2       no\n",
            "j    dog  3.0       1       no\n"
          ]
        }
      ],
      "source": [
        "# Add a new row 'k'\n",
        "df.loc['k'] = ['dog', 2.5, 2, 'no']\n",
        "\n",
        "print(df)\n",
        "\n",
        "# Delete the row 'k'\n",
        "df = df.drop('k')\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWXhPaG2j5Jd"
      },
      "source": [
        "**17.** Count the number of each type of animal in `df`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "id": "oD53Sj7Vj5Jd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c5364f0-80f1-49dd-9b90-8e4b4c494e73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "animal\n",
            "cat      4\n",
            "dog      4\n",
            "snake    2\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "animal_counts = df['animal'].value_counts()\n",
        "print(animal_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soARftskj5Jd"
      },
      "source": [
        "**18.** Sort `df` first by the values in the 'age' in *decending* order, then by the value in the 'visit' column in *ascending* order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "collapsed": true,
        "id": "-24gZRUwj5Jd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85b18357-4b15-454b-d646-bf1f48c9c1f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  animal  age  visits priority\n",
            "i    dog  7.0       2       no\n",
            "e    dog  5.0       2       no\n",
            "g  snake  4.5       1       no\n",
            "j    dog  3.0       1       no\n",
            "b    cat  3.0       3      yes\n",
            "a    cat  2.5       1      yes\n",
            "f    cat  1.5       3       no\n",
            "c  snake  0.5       2       no\n",
            "h    cat  NaN       1      yes\n",
            "d    dog  NaN       3      yes\n"
          ]
        }
      ],
      "source": [
        "sorted_df = df.sort_values(by=['age', 'visits'], ascending=[False, True])\n",
        "print(sorted_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUKLlbU_j5Je"
      },
      "source": [
        "**19.** The 'priority' column contains the values 'yes' and 'no'. Replace this column with a column of boolean values: 'yes' should be `True` and 'no' should be `False`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "collapsed": true,
        "id": "dG4EXsRJj5Je",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cde58d3f-4fa5-45d7-da3c-b9b7c35cc8df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  animal  age  visits  priority\n",
            "a    cat  2.5       1      True\n",
            "b    cat  3.0       3      True\n",
            "c  snake  0.5       2     False\n",
            "d    dog  NaN       3      True\n",
            "e    dog  5.0       2     False\n",
            "f    cat  1.5       3     False\n",
            "g  snake  4.5       1     False\n",
            "h    cat  NaN       1      True\n",
            "i    dog  7.0       2     False\n",
            "j    dog  3.0       1     False\n"
          ]
        }
      ],
      "source": [
        "df['priority'] = df['priority'] == 'yes'\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-bBBG6Mj5Jf"
      },
      "source": [
        "**20.** In the 'animal' column, change the 'snake' entries to 'python'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "collapsed": true,
        "id": "Yg2omZqMj5Jf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "872cb444-282c-4ad7-9697-5310c9cb07ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   animal  age  visits  priority\n",
            "a     cat  2.5       1      True\n",
            "b     cat  3.0       3      True\n",
            "c  python  0.5       2     False\n",
            "d     dog  NaN       3      True\n",
            "e     dog  5.0       2     False\n",
            "f     cat  1.5       3     False\n",
            "g  python  4.5       1     False\n",
            "h     cat  NaN       1      True\n",
            "i     dog  7.0       2     False\n",
            "j     dog  3.0       1     False\n"
          ]
        }
      ],
      "source": [
        "df['animal'] = df['animal'].replace('snake', 'python')\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQFeRlakj5Jf"
      },
      "source": [
        "**21.** For each animal type and each number of visits, find the mean age. In other words, each row is an animal, each column is a number of visits and the values are the mean ages (hint: use a pivot table)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "collapsed": true,
        "id": "170YLcP0j5Jf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "022fae31-322b-4091-e432-2172f3efd2f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "visits    1    2     3\n",
            "animal                \n",
            "cat     2.5  NaN  2.25\n",
            "dog     3.0  6.0   NaN\n",
            "python  4.5  0.5   NaN\n"
          ]
        }
      ],
      "source": [
        "pivot_table = df.pivot_table(values='age', index='animal', columns='visits', aggfunc='mean')\n",
        "print(pivot_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSC8itiQj5Jg"
      },
      "source": [
        "## DataFrames: beyond the basics\n",
        "\n",
        "### Slightly trickier: you may need to combine two or more methods to get the right answer\n",
        "\n",
        "Difficulty: *medium*\n",
        "\n",
        "The previous section was tour through some basic but essential DataFrame operations. Below are some ways that you might need to cut your data, but for which there is no single \"out of the box\" method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DWY0Ouej5Jg"
      },
      "source": [
        "**22.** You have a DataFrame `df` with a column 'A' of integers. For example:\n",
        "```python\n",
        "df = pd.DataFrame({'A': [1, 2, 2, 3, 4, 5, 5, 5, 6, 7, 7]})\n",
        "```\n",
        "\n",
        "How do you filter out rows which contain the same integer as the row immediately above?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "collapsed": true,
        "id": "U5grjQuRj5Jg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16132c61-c7dd-41cf-f259-c646691f95bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   A\n",
            "0  1\n",
            "1  2\n",
            "3  3\n",
            "4  4\n",
            "5  5\n",
            "8  6\n",
            "9  7\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({'A': [1, 2, 2, 3, 4, 5, 5, 5, 6, 7, 7]})\n",
        "\n",
        "# Create a new column to compare the current value with the previous one\n",
        "df['A_shifted'] = df['A'].shift(1)\n",
        "\n",
        "# Filter out rows where the current value is equal to the previous one\n",
        "filtered_df = df[df['A'] != df['A_shifted']]\n",
        "\n",
        "# Drop the temporary column\n",
        "filtered_df = filtered_df.drop('A_shifted', axis=1)\n",
        "\n",
        "print(filtered_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTsfsZAQj5Jg"
      },
      "source": [
        "**23.** Given a DataFrame of numeric values, say\n",
        "```python\n",
        "df = pd.DataFrame(np.random.random(size=(5, 3))) # a 5x3 frame of float values\n",
        "```\n",
        "\n",
        "how do you subtract the row mean from each element in the row?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "collapsed": true,
        "id": "-xu6aXObj5Jg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42ab56c9-e558-45e3-d77f-b814bb6792e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          0         1         2\n",
            "0  0.204705 -0.390764  0.186059\n",
            "1  0.374633 -0.126885 -0.247748\n",
            "2 -0.364867 -0.009435  0.374303\n",
            "3  0.156280  0.236138 -0.392418\n",
            "4  0.022406 -0.009728 -0.012677\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "df = pd.DataFrame(np.random.random(size=(5, 3)))\n",
        "\n",
        "# Calculate the row means\n",
        "row_means = df.mean(axis=1)\n",
        "\n",
        "# Subtract the row means from each element\n",
        "df_normalized = df.sub(row_means, axis=0)\n",
        "\n",
        "print(df_normalized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aW758simj5Jg"
      },
      "source": [
        "**24.** Suppose you have DataFrame with 10 columns of real numbers, for example:\n",
        "\n",
        "```python\n",
        "df = pd.DataFrame(np.random.random(size=(5, 10)), columns=list('abcdefghij'))\n",
        "```\n",
        "Which column of numbers has the smallest sum? (Find that column's label.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "collapsed": true,
        "id": "J33jX4iBj5Jg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54ba03a1-8fd2-4587-fbb0-3b4b4d522e5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column with the smallest sum: g\n"
          ]
        }
      ],
      "source": [
        "\n",
        "df = pd.DataFrame(np.random.random(size=(5, 10)), columns=list('abcdefghij'))\n",
        "\n",
        "# Calculate the sum of each column\n",
        "column_sums = df.sum()\n",
        "\n",
        "# Find the column with the smallest sum\n",
        "min_sum_column = column_sums.idxmin()\n",
        "\n",
        "print(\"Column with the smallest sum:\", min_sum_column)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KdIe5Svj5Jh"
      },
      "source": [
        "**25.** How do you count how many unique rows a DataFrame has (i.e. ignore all rows that are duplicates)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "collapsed": true,
        "id": "dczxM9oRj5Jh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2026d3d1-a8d4-4a70-8192-82bf71292053"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique rows: 7\n"
          ]
        }
      ],
      "source": [
        "# Create a sample DataFrame with duplicate rows\n",
        "df = pd.DataFrame({'A': [1, 2, 2, 3, 4, 5, 5, 5, 6, 7, 7],\n",
        "                    'B': [10, 20, 20, 30, 40, 50, 50, 50, 60, 70, 70]})\n",
        "\n",
        "# Count unique rows\n",
        "unique_rows = df.drop_duplicates().shape[0]\n",
        "\n",
        "print(\"Number of unique rows:\", unique_rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-eB9pejj5Jh"
      },
      "source": [
        "The next three puzzles are slightly harder...\n",
        "\n",
        "**26.** You have a DataFrame that consists of 10 columns of floating--point numbers. Suppose that exactly 5 entries in each row are NaN values. For each row of the DataFrame, find the *column* which contains the *third* NaN value.\n",
        "\n",
        "(You should return a Series of column labels.)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sample DataFrame with 5 NaN values per row\n",
        "df = pd.DataFrame(np.random.randn(10, 10))\n",
        "df.iloc[::2, :5] = np.nan  # Set the first 5 columns of every other row to NaN\n",
        "\n",
        "# Function to find the column index of the third NaN value in a row\n",
        "def find_third_nan_column(row):\n",
        "    nan_counts = row.isna().cumsum()\n",
        "    # Check if there's a third NaN value before accessing the index\n",
        "    if (nan_counts == 3).any():\n",
        "        return nan_counts[nan_counts == 3].index[0]\n",
        "    else:\n",
        "        return np.nan  # Return NaN if no third NaN value is found\n",
        "\n",
        "# Apply the function to each row and get the column labels\n",
        "third_nan_columns = df.apply(find_third_nan_column, axis=1)\n",
        "\n",
        "print(third_nan_columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRuX8y8CeBRQ",
        "outputId": "7d2415a8-a87d-4394-fc7c-c1072fca1d92"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    2.0\n",
            "1    NaN\n",
            "2    2.0\n",
            "3    NaN\n",
            "4    2.0\n",
            "5    NaN\n",
            "6    2.0\n",
            "7    NaN\n",
            "8    2.0\n",
            "9    NaN\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spyC9O6qj5Jh"
      },
      "source": [
        "**27.** A DataFrame has a column of groups 'grps' and and column of numbers 'vals'. For example:\n",
        "\n",
        "```python\n",
        "df = pd.DataFrame({'grps': list('aaabbcaabcccbbc'),\n",
        "                   'vals': [12,345,3,1,45,14,4,52,54,23,235,21,57,3,87]})\n",
        "```\n",
        "For each *group*, find the sum of the three greatest values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "collapsed": true,
        "id": "_UtBlCgHj5Jh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac65c714-5ca3-450d-cf63-5708653b6980"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   grps  vals  top_3_sum\n",
            "0     a    12        409\n",
            "1     a   345        409\n",
            "2     a     3        409\n",
            "3     b     1        156\n",
            "4     b    45        156\n",
            "5     c    14        345\n",
            "6     a     4        409\n",
            "7     a    52        409\n",
            "8     b    54        156\n",
            "9     c    23        345\n",
            "10    c   235        345\n",
            "11    c    21        345\n",
            "12    b    57        156\n",
            "13    b     3        156\n",
            "14    c    87        345\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame({'grps': list('aaabbcaabcccbbc'), 'vals': [12, 345, 3, 1, 45, 14, 4, 52, 54, 23, 235, 21, 57, 3, 87]})\n",
        "def g(df):\n",
        "    df['top_3_sum'] = df.groupby('grps')['vals'].transform(lambda x: x.nlargest(3).sum())\n",
        "    return df\n",
        "\n",
        "df = g(df.copy())\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYiyysKqj5Ji"
      },
      "source": [
        "**28.** A DataFrame has two integer columns 'A' and 'B'. The values in 'A' are between 1 and 100 (inclusive). For each group of 10 consecutive integers in 'A' (i.e. `(0, 10]`, `(10, 20]`, ...), calculate the sum of the corresponding values in column 'B'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "collapsed": true,
        "id": "RAZ7yE36j5Ji",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71f8d578-185f-465b-b772-f49d05592c1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "group\n",
            "[0, 10)        285\n",
            "[10, 20)      2185\n",
            "[20, 30)      6085\n",
            "[30, 40)     11985\n",
            "[40, 50)     19885\n",
            "[50, 60)     29785\n",
            "[60, 70)     41685\n",
            "[70, 80)     55585\n",
            "[80, 90)     71485\n",
            "[90, 100)    89385\n",
            "Name: B, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-788b885c0c03>:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  result = df.groupby('group')['B'].sum()\n"
          ]
        }
      ],
      "source": [
        "# Sample DataFrame\n",
        "df = pd.DataFrame({'A': range(1, 101), 'B': [i**2 for i in range(1, 101)]})\n",
        "\n",
        "# Define bins for grouping\n",
        "bins = range(0, 110, 10)\n",
        "\n",
        "# Group by bins and calculate the sum of 'B'\n",
        "df['group'] = pd.cut(df['A'], bins=bins, right=False)\n",
        "result = df.groupby('group')['B'].sum()\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErJqCEw2j5Ji"
      },
      "source": [
        "## DataFrames: harder problems\n",
        "\n",
        "### These might require a bit of thinking outside the box...\n",
        "\n",
        "...but all are solvable using just the usual pandas/NumPy methods (and so avoid using explicit `for` loops).\n",
        "\n",
        "Difficulty: *hard*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLQLM-raj5Ji"
      },
      "source": [
        "**29.** Consider a DataFrame `df` where there is an integer column 'X':\n",
        "```python\n",
        "df = pd.DataFrame({'X': [7, 2, 0, 3, 4, 2, 5, 0, 3, 4]})\n",
        "```\n",
        "For each value, count the difference back to the previous zero (or the start of the Series, whichever is closer). These values should therefore be `[1, 2, 0, 1, 2, 3, 4, 0, 1, 2]`. Make this a new column 'Y'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "collapsed": true,
        "id": "MrBZdziPj5Ji",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "083b9062-8b29-4659-b5e9-ba4c3133289e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   X  Y\n",
            "0  7  1\n",
            "1  2  2\n",
            "2  0  0\n",
            "3  3  1\n",
            "4  4  2\n",
            "5  2  3\n",
            "6  5  4\n",
            "7  0  0\n",
            "8  3  1\n",
            "9  4  2\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame({'X': [7, 2, 0, 3, 4, 2, 5, 0, 3, 4]})\n",
        "\n",
        "def calculate_distance_to_prev_zero(series):\n",
        "    zero_indices = series[series == 0].index\n",
        "    distances = []\n",
        "    for i, val in enumerate(series):\n",
        "        if val == 0:\n",
        "            distances.append(0)\n",
        "        else:\n",
        "            closest_zero_index = zero_indices[zero_indices < i][-1] if zero_indices[zero_indices < i].size > 0 else -1\n",
        "            distances.append(i - closest_zero_index)\n",
        "    return distances\n",
        "\n",
        "df['Y'] = calculate_distance_to_prev_zero(df['X'])\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQUdEkO5j5Ji"
      },
      "source": [
        "Here's an alternative approach based on a [cookbook recipe](http://pandas.pydata.org/pandas-docs/stable/cookbook.html#grouping):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Iy3oL6vfj5Ji"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpK0LOijj5Jj"
      },
      "source": [
        "**30.** Consider a DataFrame containing rows and columns of purely numerical data. Create a list of the row-column index locations of the 3 largest values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "collapsed": true,
        "id": "oTMGmludj5Jj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b67fb7a-9cd0-4bee-d784-01e38db164be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(6, 3), (8, 3), (4, 2)]\n"
          ]
        }
      ],
      "source": [
        "# Create a sample DataFrame\n",
        "df = pd.DataFrame(np.random.randn(10, 5))\n",
        "\n",
        "# Flatten the DataFrame to a 1D array\n",
        "flattened_df = df.values.flatten()\n",
        "\n",
        "# Find the indices of the 3 largest values in the flattened array\n",
        "largest_indices = np.argsort(flattened_df)[-3:]\n",
        "\n",
        "# Convert the flat indices to row and column indices\n",
        "row_indices, col_indices = np.unravel_index(largest_indices, df.shape)\n",
        "\n",
        "# Create a list of tuples containing row and column indices\n",
        "largest_value_indices = list(zip(row_indices, col_indices))\n",
        "\n",
        "print(largest_value_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZK8aRKWj5Jj"
      },
      "source": [
        "**31.** Given a DataFrame with a column of group IDs, 'grps', and a column of corresponding integer values, 'vals', replace any negative values in 'vals' with the group mean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "collapsed": true,
        "id": "hvJpQbgpj5Jj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e74ab41-5e4f-44f4-fea2-871ee6570418"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  grps  vals\n",
            "0    A  10.0\n",
            "1    A   2.5\n",
            "2    B   2.0\n",
            "3    B  -0.5\n",
            "4    C   4.0\n",
            "5    C   1.5\n"
          ]
        }
      ],
      "source": [
        "# Sample DataFrame\n",
        "df = pd.DataFrame({'grps': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
        "                   'vals': [10, -5, 2, -3, 4, -1]})\n",
        "\n",
        "# Calculate the group means\n",
        "group_means = df.groupby('grps')['vals'].transform('mean')\n",
        "\n",
        "# Replace negative values with the group mean\n",
        "df['vals'] = df['vals'].where(df['vals'] >= 0, group_means)\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYAmaXSSj5Jj"
      },
      "source": [
        "**32.** Implement a rolling mean over groups with window size 3, which ignores NaN value. For example consider the following DataFrame:\n",
        "\n",
        "```python\n",
        ">>> df = pd.DataFrame({'group': list('aabbabbbabab'),\n",
        "                       'value': [1, 2, 3, np.nan, 2, 3,\n",
        "                                 np.nan, 1, 7, 3, np.nan, 8]})\n",
        ">>> df\n",
        "   group  value\n",
        "0      a    1.0\n",
        "1      a    2.0\n",
        "2      b    3.0\n",
        "3      b    NaN\n",
        "4      a    2.0\n",
        "5      b    3.0\n",
        "6      b    NaN\n",
        "7      b    1.0\n",
        "8      a    7.0\n",
        "9      b    3.0\n",
        "10     a    NaN\n",
        "11     b    8.0\n",
        "```\n",
        "The goal is to compute the Series:\n",
        "\n",
        "```\n",
        "0     1.000000\n",
        "1     1.500000\n",
        "2     3.000000\n",
        "3     3.000000\n",
        "4     1.666667\n",
        "5     3.000000\n",
        "6     3.000000\n",
        "7     2.000000\n",
        "8     3.666667\n",
        "9     2.000000\n",
        "10    4.500000\n",
        "11    4.000000\n",
        "```\n",
        "E.g. the first window of size three for group 'b' has values 3.0, NaN and 3.0 and occurs at row index 5. Instead of being NaN the value in the new column at this row index should be 3.0 (just the two non-NaN values are used to compute the mean (3+3)/2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "collapsed": true,
        "id": "AGPEhGiBj5Jj"
      },
      "outputs": [],
      "source": [
        "def rolling_mean_ignoring_nan(df, group_col, value_col, window_size):\n",
        "    def rolling_mean_helper(group):\n",
        "        group = group.reset_index(drop=True)\n",
        "        rolling_mean = group[value_col].rolling(window=window_size).mean()\n",
        "\n",
        "        # Handle the first window with potential NaN values\n",
        "        first_window_mean = group[value_col][:window_size].dropna().mean()\n",
        "        rolling_mean.iloc[window_size - 1] = first_window_mean\n",
        "\n",
        "        return rolling_mean\n",
        "\n",
        "    return df.groupby(group_col).apply(rolling_mean_helper).reset_index(level=0, drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkJ0eRfBj5Jj"
      },
      "source": [
        "## Series and DatetimeIndex\n",
        "\n",
        "### Exercises for creating and manipulating Series with datetime data\n",
        "\n",
        "Difficulty: *easy/medium*\n",
        "\n",
        "pandas is fantastic for working with dates and times. These puzzles explore some of this functionality.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMw_qAGfj5Jk"
      },
      "source": [
        "**33.** Create a DatetimeIndex that contains each business day of 2015 and use it to index a Series of random numbers. Let's call this Series `s`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "collapsed": true,
        "id": "dUB35rJZj5Jk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66e03b60-8caa-4801-95e6-dc63b8109116"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2015-01-01    1.631477\n",
            "2015-01-02   -0.737893\n",
            "2015-01-05   -0.226328\n",
            "2015-01-06   -0.944973\n",
            "2015-01-07    1.118434\n",
            "                ...   \n",
            "2015-12-25   -0.966398\n",
            "2015-12-28    0.550769\n",
            "2015-12-29    1.636466\n",
            "2015-12-30    1.363007\n",
            "2015-12-31    0.354807\n",
            "Freq: B, Length: 261, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Create a DatetimeIndex for all business days in 2015\n",
        "index = pd.bdate_range(start='2015-01-01', end='2015-12-31')\n",
        "\n",
        "# Create a Series of random numbers with the DatetimeIndex\n",
        "s = pd.Series(np.random.randn(len(index)), index=index)\n",
        "\n",
        "print(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O-kUcYEj5Jk"
      },
      "source": [
        "**34.** Find the sum of the values in `s` for every Wednesday."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "collapsed": true,
        "id": "KSzlMNg1j5Jk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40afe0f7-4dd3-4e0f-f224-bbb181a8fe1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum of values on Wednesdays: 7.792945026195682\n"
          ]
        }
      ],
      "source": [
        "# Filter for Wednesdays and calculate the sum\n",
        "wednesdays_data = s[s.index.weekday == 2]\n",
        "wednesday_sum = wednesdays_data.sum()\n",
        "\n",
        "print(\"Sum of values on Wednesdays:\", wednesday_sum)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T86hv86j5Jk"
      },
      "source": [
        "**35.** For each calendar month in `s`, find the mean of values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "collapsed": true,
        "id": "xxIrFL_wj5Jl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b9872db-2925-41e4-fcdd-0c526b43ff27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2015-01-31   -0.164656\n",
            "2015-02-28    0.478711\n",
            "2015-03-31    0.049705\n",
            "2015-04-30    0.007113\n",
            "2015-05-31   -0.067084\n",
            "2015-06-30    0.063234\n",
            "2015-07-31   -0.107729\n",
            "2015-08-31    0.151574\n",
            "2015-09-30    0.082085\n",
            "2015-10-31    0.187279\n",
            "2015-11-30   -0.160130\n",
            "2015-12-31    0.117298\n",
            "Freq: ME, dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-c0b46b6791b5>:2: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
            "  monthly_means = s.groupby(pd.Grouper(freq='M')).mean()\n"
          ]
        }
      ],
      "source": [
        "# Group the Series by month and calculate the mean\n",
        "monthly_means = s.groupby(pd.Grouper(freq='M')).mean()\n",
        "\n",
        "print(monthly_means)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T53qV2amj5Jl"
      },
      "source": [
        "**36.** For each group of four consecutive calendar months in `s`, find the date on which the highest value occurred."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "collapsed": true,
        "id": "Xa6PrWY_j5Jl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2039bb0-188c-4d7d-97de-b38d0aa8c6f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2015-01-31   2015-01-01\n",
            "2015-05-31   2015-04-20\n",
            "2015-09-30   2015-07-23\n",
            "2016-01-31   2015-11-27\n",
            "Freq: 4ME, dtype: datetime64[ns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-d51ef864afdf>:2: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
            "  max_dates = s.groupby(pd.Grouper(freq='4M')).idxmax()\n"
          ]
        }
      ],
      "source": [
        "# Group the Series by 4-month periods and find the index of the maximum value\n",
        "max_dates = s.groupby(pd.Grouper(freq='4M')).idxmax()\n",
        "\n",
        "print(max_dates)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sw0UhhKj5Jl"
      },
      "source": [
        "**37.** Create a DateTimeIndex consisting of the third Thursday in each month for the years 2015 and 2016."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "collapsed": true,
        "id": "qkNABM7_j5Jl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9189de52-a9e5-42c5-c1a9-f846a21a0a2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatetimeIndex(['2015-01-15', '2015-02-19', '2015-03-19', '2015-04-16',\n",
            "               '2015-05-21', '2015-06-18', '2015-07-16', '2015-08-20',\n",
            "               '2015-09-17', '2015-10-15', '2015-11-19', '2015-12-17',\n",
            "               '2016-01-21', '2016-02-18', '2016-03-17', '2016-04-21',\n",
            "               '2016-05-19', '2016-06-16', '2016-07-21', '2016-08-18',\n",
            "               '2016-09-15', '2016-10-20', '2016-11-17', '2016-12-15'],\n",
            "              dtype='datetime64[ns]', freq='WOM-3THU')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a date range for each year, specifying the frequency as the third Thursday of each month\n",
        "start_date_2015 = '2015-01-01'\n",
        "end_date_2015 = '2015-12-31'\n",
        "start_date_2016 = '2016-01-01'\n",
        "end_date_2016 = '2016-12-31'\n",
        "\n",
        "# Create DateTimeIndex for each year\n",
        "dt_index_2015 = pd.date_range(start=start_date_2015, end=end_date_2015, freq='WOM-3THU')\n",
        "dt_index_2016 = pd.date_range(start=start_date_2016, end=end_date_2016, freq='WOM-3THU')\n",
        "\n",
        "# Combine the two DateTimeIndexes\n",
        "dt_index = dt_index_2015.union(dt_index_2016)\n",
        "\n",
        "print(dt_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IoDHj4Aj5Jm"
      },
      "source": [
        "## Cleaning Data\n",
        "\n",
        "### Making a DataFrame easier to work with\n",
        "\n",
        "Difficulty: *easy/medium*\n",
        "\n",
        "It happens all the time: someone gives you data containing malformed strings, Python, lists and missing data. How do you tidy it up so you can get on with the analysis?\n",
        "\n",
        "Take this monstrosity as the DataFrame to use in the following puzzles:\n",
        "\n",
        "```python\n",
        "df = pd.DataFrame({'From_To': ['LoNDon_paris', 'MAdrid_miLAN', 'londON_StockhOlm',\n",
        "                               'Budapest_PaRis', 'Brussels_londOn'],\n",
        "              'FlightNumber': [10045, np.nan, 10065, np.nan, 10085],\n",
        "              'RecentDelays': [[23, 47], [], [24, 43, 87], [13], [67, 32]],\n",
        "                   'Airline': ['KLM(!)', '<Air France> (12)', '(British Airways. )',\n",
        "                               '12. Air France', '\"Swiss Air\"']})\n",
        "```\n",
        "(It's some flight data I made up; it's not meant to be accurate in any way.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_YB5KVBj5Jm"
      },
      "source": [
        "**38.** Some values in the the FlightNumber column are missing. These numbers are meant to increase by 10 with each row so 10055 and 10075 need to be put in place. Fill in these missing numbers and make the column an integer column (instead of a float column)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "collapsed": true,
        "id": "xj7Za_qBj5Jm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab53710a-b43f-45e4-bea7-898fd72717c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            From_To  FlightNumber  RecentDelays              Airline\n",
            "0      LoNDon_paris         10055      [23, 47]               KLM(!)\n",
            "1      MAdrid_miLAN         10055            []    <Air France> (12)\n",
            "2  londON_StockhOlm         10075  [24, 43, 87]  (British Airways. )\n",
            "3    Budapest_PaRis         10075          [13]       12. Air France\n",
            "4   Brussels_londOn         10095      [67, 32]          \"Swiss Air\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-40-c23261f2c5a1>:8: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df['FlightNumber'] = df['FlightNumber'].fillna(method='ffill') + 10\n"
          ]
        }
      ],
      "source": [
        "# Create the DataFrame\n",
        "df = pd.DataFrame({'From_To': ['LoNDon_paris', 'MAdrid_miLAN', 'londON_StockhOlm', 'Budapest_PaRis', 'Brussels_londOn'],\n",
        "                   'FlightNumber': [10045, np.nan, 10065, np.nan, 10085],\n",
        "                   'RecentDelays': [[23, 47], [], [24, 43, 87], [13], [67, 32]],\n",
        "                   'Airline': ['KLM(!)', '<Air France> (12)', '(British Airways. )', '12. Air France', '\"Swiss Air\"']})\n",
        "\n",
        "# Fill missing FlightNumber values\n",
        "df['FlightNumber'] = df['FlightNumber'].fillna(method='ffill') + 10\n",
        "\n",
        "# Convert the FlightNumber column to integer\n",
        "df['FlightNumber'] = df['FlightNumber'].astype(int)\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgymOK6Hj5Jn"
      },
      "source": [
        "**39.** The From\\_To column would be better as two separate columns! Split each string on the underscore delimiter `_` to give a new temporary DataFrame with the correct values. Assign the correct column names to this temporary DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "collapsed": true,
        "id": "T77dnAGbj5Jn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe644e44-44ac-4ba2-8773-364ae5e529ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       From         To  FlightNumber  RecentDelays              Airline\n",
            "0    LoNDon      paris       10045.0      [23, 47]               KLM(!)\n",
            "1    MAdrid      miLAN           NaN            []    <Air France> (12)\n",
            "2    londON  StockhOlm       10065.0  [24, 43, 87]  (British Airways. )\n",
            "3  Budapest      PaRis           NaN          [13]       12. Air France\n",
            "4  Brussels     londOn       10085.0      [67, 32]          \"Swiss Air\"\n"
          ]
        }
      ],
      "source": [
        "# Create the DataFrame\n",
        "df = pd.DataFrame({'From_To': ['LoNDon_paris', 'MAdrid_miLAN', 'londON_StockhOlm', 'Budapest_PaRis', 'Brussels_londOn'],\n",
        "                   'FlightNumber': [10045, np.nan, 10065, np.nan, 10085],\n",
        "                   'RecentDelays': [[23, 47], [], [24, 43, 87], [13], [67, 32]],\n",
        "                   'Airline': ['KLM(!)', '<Air France> (12)', '(British Airways. )', '12. Air France', '\"Swiss Air\"']})\n",
        "\n",
        "# Split the 'From_To' column and create a temporary DataFrame\n",
        "temp_df = df['From_To'].str.split('_', expand=True)\n",
        "\n",
        "# Assign column names to the temporary DataFrame\n",
        "temp_df.columns = ['From', 'To']\n",
        "\n",
        "# Concatenate the temporary DataFrame with the original DataFrame, dropping the original 'From_To' column\n",
        "df = pd.concat([temp_df, df.drop('From_To', axis=1)], axis=1)\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSNMI8KKj5Jn"
      },
      "source": [
        "**40.** Notice how the capitalisation of the city names is all mixed up in this temporary DataFrame. Standardise the strings so that only the first letter is uppercase (e.g. \"londON\" should become \"London\".)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "collapsed": true,
        "id": "FsC_2ybfj5Jn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6ee3120-f69d-4e36-ab45-b4474a4b68e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       From         To  FlightNumber  RecentDelays              Airline\n",
            "0    London      Paris       10045.0      [23, 47]               KLM(!)\n",
            "1    Madrid      Milan           NaN            []    <Air France> (12)\n",
            "2    London  Stockholm       10065.0  [24, 43, 87]  (British Airways. )\n",
            "3  Budapest      Paris           NaN          [13]       12. Air France\n",
            "4  Brussels     London       10085.0      [67, 32]          \"Swiss Air\"\n"
          ]
        }
      ],
      "source": [
        "# Create the DataFrame\n",
        "df = pd.DataFrame({'From_To': ['LoNDon_paris', 'MAdrid_miLAN', 'londON_StockhOlm', 'Budapest_PaRis', 'Brussels_londOn'],\n",
        "                   'FlightNumber': [10045, np.nan, 10065, np.nan, 10085],\n",
        "                   'RecentDelays': [[23, 47], [], [24, 43, 87], [13], [67, 32]],\n",
        "                   'Airline': ['KLM(!)', '<Air France> (12)', '(British Airways. )', '12. Air France', '\"Swiss Air\"']})\n",
        "\n",
        "# Split the 'From_To' column and create a temporary DataFrame\n",
        "temp_df = df['From_To'].str.split('_', expand=True)\n",
        "\n",
        "# Assign column names to the temporary DataFrame\n",
        "temp_df.columns = ['From', 'To']\n",
        "\n",
        "# Standardize capitalization in 'From' and 'To' columns\n",
        "temp_df['From'] = temp_df['From'].str.title()\n",
        "temp_df['To'] = temp_df['To'].str.title()\n",
        "\n",
        "# Concatenate the temporary DataFrame with the original DataFrame, dropping the original 'From_To' column\n",
        "df = pd.concat([temp_df, df.drop('From_To', axis=1)], axis=1)\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MciVXlKpj5Jn"
      },
      "source": [
        "**41.** Delete the From_To column from `df` and attach the temporary DataFrame from the previous questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "collapsed": true,
        "id": "FGsUydmwj5Jo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c06080c-cf7c-4467-ed59-6aa823c9e73a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       From         To  FlightNumber  RecentDelays              Airline\n",
            "0    London      Paris       10045.0      [23, 47]               KLM(!)\n",
            "1    Madrid      Milan           NaN            []    <Air France> (12)\n",
            "2    London  Stockholm       10065.0  [24, 43, 87]  (British Airways. )\n",
            "3  Budapest      Paris           NaN          [13]       12. Air France\n",
            "4  Brussels     London       10085.0      [67, 32]          \"Swiss Air\"\n"
          ]
        }
      ],
      "source": [
        "# Create the DataFrame\n",
        "df = pd.DataFrame({'From_To': ['LoNDon_paris', 'MAdrid_miLAN', 'londON_StockhOlm', 'Budapest_PaRis', 'Brussels_londOn'],\n",
        "                   'FlightNumber': [10045, np.nan, 10065, np.nan, 10085],\n",
        "                   'RecentDelays': [[23, 47], [], [24, 43, 87], [13], [67, 32]],\n",
        "                   'Airline': ['KLM(!)', '<Air France> (12)', '(British Airways. )', '12. Air France', '\"Swiss Air\"']})\n",
        "\n",
        "# Split the 'From_To' column and create a temporary DataFrame\n",
        "temp_df = df['From_To'].str.split('_', expand=True)\n",
        "\n",
        "# Assign column names to the temporary DataFrame\n",
        "temp_df.columns = ['From', 'To']\n",
        "\n",
        "# Standardize capitalization in 'From' and 'To' columns\n",
        "temp_df['From'] = temp_df['From'].str.title()\n",
        "temp_df['To'] = temp_df['To'].str.title()\n",
        "\n",
        "# Drop the 'From_To' column from the original DataFrame\n",
        "df.drop('From_To', axis=1, inplace=True)\n",
        "\n",
        "# Concatenate the temporary DataFrame with the original DataFrame\n",
        "df = pd.concat([temp_df, df], axis=1)\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2HhMIG3j5Jo"
      },
      "source": [
        "**42**. In the Airline column, you can see some extra puctuation and symbols have appeared around the airline names. Pull out just the airline name. E.g. `'(British Airways. )'` should become `'British Airways'`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "collapsed": true,
        "id": "NZMBM65mj5Jo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cc163d5-38fa-42aa-b4ee-f304396189e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       From         To  FlightNumber  RecentDelays          Airline\n",
            "0    London      Paris       10045.0      [23, 47]              KLM\n",
            "1    Madrid      Milan           NaN            []       Air France\n",
            "2    London  Stockholm       10065.0  [24, 43, 87]  British Airways\n",
            "3  Budapest      Paris           NaN          [13]       Air France\n",
            "4  Brussels     London       10085.0      [67, 32]        Swiss Air\n"
          ]
        }
      ],
      "source": [
        "# Create the DataFrame\n",
        "df = pd.DataFrame({'From_To': ['LoNDon_paris', 'MAdrid_miLAN', 'londON_StockhOlm', 'Budapest_PaRis', 'Brussels_londOn'],\n",
        "                   'FlightNumber': [10045, np.nan, 10065, np.nan, 10085],\n",
        "                   'RecentDelays': [[23, 47], [], [24, 43, 87], [13], [67, 32]],\n",
        "                   'Airline': ['KLM(!)', '<Air France> (12)', '(British Airways. )', '12. Air France', '\"Swiss Air\"']})\n",
        "\n",
        "# Split the 'From_To' column and create a temporary DataFrame\n",
        "temp_df = df['From_To'].str.split('_', expand=True)\n",
        "\n",
        "# Assign column names to the temporary DataFrame\n",
        "temp_df.columns = ['From', 'To']\n",
        "\n",
        "# Standardize capitalization in 'From' and 'To' columns\n",
        "temp_df['From'] = temp_df['From'].str.title()\n",
        "temp_df['To'] = temp_df['To'].str.title()\n",
        "\n",
        "# Drop the 'From_To' column from the original DataFrame\n",
        "df.drop('From_To', axis=1, inplace=True)\n",
        "\n",
        "# Concatenate the temporary DataFrame with the original DataFrame\n",
        "df = pd.concat([temp_df, df], axis=1)\n",
        "\n",
        "# Clean the Airline column\n",
        "df['Airline'] = df['Airline'].str.extract('([A-Za-z\\s]+)')\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxS6XSwOj5Jo"
      },
      "source": [
        "**43**. In the RecentDelays column, the values have been entered into the DataFrame as a list. We would like each first value in its own column, each second value in its own column, and so on. If there isn't an Nth value, the value should be NaN.\n",
        "\n",
        "Expand the Series of lists into a DataFrame named `delays`, rename the columns `delay_1`, `delay_2`, etc. and replace the unwanted RecentDelays column in `df` with `delays`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "collapsed": true,
        "id": "WMZF-xbJj5Jo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdf02af1-3b8c-48f4-b3c4-5d105071389a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       From         To  FlightNumber          Airline  delay_1  delay_2  \\\n",
            "0    London      Paris       10045.0              KLM     23.0     47.0   \n",
            "1    Madrid      Milan           NaN       Air France      NaN      NaN   \n",
            "2    London  Stockholm       10065.0  British Airways     24.0     43.0   \n",
            "3  Budapest      Paris           NaN       Air France     13.0      NaN   \n",
            "4  Brussels     London       10085.0        Swiss Air     67.0     32.0   \n",
            "\n",
            "   delay_3  \n",
            "0      NaN  \n",
            "1      NaN  \n",
            "2     87.0  \n",
            "3      NaN  \n",
            "4      NaN  \n"
          ]
        }
      ],
      "source": [
        "# Create the DataFrame\n",
        "df = pd.DataFrame({'From_To': ['LoNDon_paris', 'MAdrid_miLAN', 'londON_StockhOlm', 'Budapest_PaRis', 'Brussels_londOn'],\n",
        "                   'FlightNumber': [10045, np.nan, 10065, np.nan, 10085],\n",
        "                   'RecentDelays': [[23, 47], [], [24, 43, 87], [13], [67, 32]],\n",
        "                   'Airline': ['KLM(!)', '<Air France> (12)', '(British Airways. )', '12. Air France', '\"Swiss Air\"']})\n",
        "\n",
        "# Split the 'From_To' column and create a temporary DataFrame\n",
        "temp_df = df['From_To'].str.split('_', expand=True)\n",
        "\n",
        "# Assign column names to the temporary DataFrame\n",
        "temp_df.columns = ['From', 'To']\n",
        "\n",
        "# Standardize capitalization in 'From' and 'To' columns\n",
        "temp_df['From'] = temp_df['From'].str.title()\n",
        "temp_df['To'] = temp_df['To'].str.title()\n",
        "\n",
        "# Drop the 'From_To' column from the original DataFrame\n",
        "df.drop('From_To', axis=1, inplace=True)\n",
        "\n",
        "# Concatenate the temporary DataFrame with the original DataFrame\n",
        "df = pd.concat([temp_df, df], axis=1)\n",
        "\n",
        "# Clean the Airline column\n",
        "df['Airline'] = df['Airline'].str.extract('([A-Za-z\\s]+)')\n",
        "\n",
        "# Expand the 'RecentDelays' column into a DataFrame\n",
        "delays = pd.DataFrame(df['RecentDelays'].tolist(), columns=['delay_1', 'delay_2', 'delay_3'])\n",
        "\n",
        "# Drop the 'RecentDelays' column from the original DataFrame\n",
        "df.drop('RecentDelays', axis=1, inplace=True)\n",
        "\n",
        "# Concatenate the expanded 'delays' DataFrame with the original DataFrame\n",
        "df = pd.concat([df, delays], axis=1)\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxvL19ozj5Jo"
      },
      "source": [
        "The DataFrame should look much better now."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "OtE5ngmvj5Jp"
      },
      "source": [
        "## Using MultiIndexes\n",
        "\n",
        "### Go beyond flat DataFrames with additional index levels\n",
        "\n",
        "Difficulty: *medium*\n",
        "\n",
        "Previous exercises have seen us analysing data from DataFrames equipped with a single index level. However, pandas also gives you the possibilty of indexing your data using *multiple* levels. This is very much like adding new dimensions to a Series or a DataFrame. For example, a Series is 1D, but by using a MultiIndex with 2 levels we gain of much the same functionality as a 2D DataFrame.\n",
        "\n",
        "The set of puzzles below explores how you might use multiple index levels to enhance data analysis.\n",
        "\n",
        "To warm up, we'll look make a Series with two index levels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9GRhkQvj5Jp"
      },
      "source": [
        "**44**. Given the lists `letters = ['A', 'B', 'C']` and `numbers = list(range(10))`, construct a MultiIndex object from the product of the two lists. Use it to index a Series of random numbers. Call this Series `s`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "collapsed": true,
        "id": "eXMCEXnrj5Jp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80d095a7-359f-4647-f8d8-a2031e4990b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "letter  number\n",
            "A       0        -2.303013\n",
            "        1         0.896554\n",
            "        2         0.474856\n",
            "        3        -0.069967\n",
            "        4         0.689171\n",
            "        5        -0.406827\n",
            "        6         0.280659\n",
            "        7        -1.074831\n",
            "        8        -1.254856\n",
            "        9        -0.389713\n",
            "B       0         0.992769\n",
            "        1        -0.879900\n",
            "        2        -0.165659\n",
            "        3        -2.071776\n",
            "        4        -0.490291\n",
            "        5        -0.848653\n",
            "        6         0.640962\n",
            "        7        -0.209035\n",
            "        8         1.255762\n",
            "        9         0.972211\n",
            "C       0        -0.611552\n",
            "        1        -0.110294\n",
            "        2        -0.693416\n",
            "        3        -0.764142\n",
            "        4         1.238794\n",
            "        5        -1.012766\n",
            "        6        -0.322182\n",
            "        7         0.627802\n",
            "        8        -0.362166\n",
            "        9         1.735810\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Create the lists\n",
        "letters = ['A', 'B', 'C']\n",
        "numbers = list(range(10))\n",
        "\n",
        "# Create a MultiIndex from the product of the two lists\n",
        "index = pd.MultiIndex.from_product([letters, numbers], names=['letter', 'number'])\n",
        "\n",
        "# Create a Series of random numbers with the MultiIndex\n",
        "s = pd.Series(np.random.randn(30), index=index)\n",
        "\n",
        "print(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eU_gGWQj5Jp"
      },
      "source": [
        "**45.** Check the index of `s` is lexicographically sorted (this is a necessary proprty for indexing to work correctly with a MultiIndex).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "collapsed": true,
        "id": "_UD_-Jegj5Jq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b24a6743-474d-4342-8247-6e346996f8b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "# Create a MultiIndex\n",
        "index = pd.MultiIndex.from_tuples([('A', 1), ('A', 2), ('B', 1), ('B', 2)])\n",
        "\n",
        "# Create a Series with the MultiIndex\n",
        "s = pd.Series([10, 20, 30, 40], index=index)\n",
        "#Sort the index\n",
        "s = s.sort_index()\n",
        "# Check lexicographical sorting using is_monotonic_increasing\n",
        "print(s.index.is_monotonic_increasing)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZUVIMt1j5Jq"
      },
      "source": [
        "**46**. Select the labels `1`, `3` and `6` from the second level of the MultiIndexed Series."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_data = s.loc[:, [1, 2]] # Selecting only existing labels in the second level\n",
        "print(selected_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yb8Nw8Sxeg34",
        "outputId": "e5908fe9-a9c7-4ca5-8665-851eefae78f2"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A  1    10\n",
            "   2    20\n",
            "B  1    30\n",
            "   2    40\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU-_xqlij5Jq"
      },
      "source": [
        "**47**. Slice the Series `s`; slice up to label 'B' for the first level and from label 5 onwards for the second level."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "collapsed": true,
        "id": "gIZ9Thwkj5Jq"
      },
      "outputs": [],
      "source": [
        "sliced_data = s.loc[pd.IndexSlice[:'B', 5:]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cieTRTYj5Jq"
      },
      "source": [
        "**48**. Sum the values in `s` for each label in the first level (you should have Series giving you a total for labels A, B and C)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "collapsed": true,
        "id": "hLo0a8Sgj5Jr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "653f554c-3b06-4366-b127-6b484dc6225e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Level letter not found'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36m_get_level_number\u001b[0;34m(self, level)\u001b[0m\n\u001b[1;32m   1663\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1664\u001b[0;31m             \u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1665\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 'letter' is not in list",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-012251c174eb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msums_by_letter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'letter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msums_by_letter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   2245\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2247\u001b[0;31m         return SeriesGroupBy(\n\u001b[0m\u001b[1;32m   2248\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2249\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgrouper\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m             grouper, exclusions, obj = get_grouper(\n\u001b[0m\u001b[1;32m   1330\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m                 \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m                 \u001b[0;31m# Get the level values from group_axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m                 \u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36mget_level_values\u001b[0;34m(self, level)\u001b[0m\n\u001b[1;32m   1830\u001b[0m         \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m         \"\"\"\n\u001b[0;32m-> 1832\u001b[0;31m         \u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_level_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1833\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1834\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36m_get_level_number\u001b[0;34m(self, level)\u001b[0m\n\u001b[1;32m   1665\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1666\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1667\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Level {level} not found\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1669\u001b[0m                 \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Level letter not found'"
          ]
        }
      ],
      "source": [
        "sums_by_letter = s.groupby(level='letter').sum()\n",
        "print(sums_by_letter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TM0P3puaj5Jr"
      },
      "source": [
        "**49**. Suppose that `sum()` (and other methods) did not accept a `level` keyword argument. How else could you perform the equivalent of `s.sum(level=1)`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "collapsed": true,
        "id": "HEgGXB-cj5Jr"
      },
      "outputs": [],
      "source": [
        "sums_by_level = s.groupby(level=1).sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi3qsJBqj5Jr"
      },
      "source": [
        "**50**. Exchange the levels of the MultiIndex so we have an index of the form (letters, numbers). Is this new Series properly lexsorted? If not, sort it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il5tLZd_j5Jr"
      },
      "source": [
        "## Minesweeper\n",
        "\n",
        "### Generate the numbers for safe squares in a Minesweeper grid\n",
        "\n",
        "Difficulty: *medium* to *hard*\n",
        "\n",
        "If you've ever used an older version of Windows, there's a good chance you've played with [Minesweeper](https://en.wikipedia.org/wiki/Minesweeper_(video_game). If you're not familiar with the game, imagine a grid of squares: some of these squares conceal a mine. If you click on a mine, you lose instantly. If you click on a safe square, you reveal a number telling you how many mines are found in the squares that are immediately adjacent. The aim of the game is to uncover all squares in the grid that do not contain a mine.\n",
        "\n",
        "In this section, we'll make a DataFrame that contains the necessary data for a game of Minesweeper: coordinates of the squares, whether the square contains a mine and the number of mines found on adjacent squares."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsITbskrj5Js"
      },
      "source": [
        "**51**. Let's suppose we're playing Minesweeper on a 5 by 4 grid, i.e.\n",
        "```\n",
        "X = 5\n",
        "Y = 4\n",
        "```\n",
        "To begin, generate a DataFrame `df` with two columns, `'x'` and `'y'` containing every coordinate for this grid. That is, the DataFrame should start:\n",
        "```\n",
        "   x  y\n",
        "0  0  0\n",
        "1  0  1\n",
        "2  0  2\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "k4n5i5MUj5Js",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0a45adb-a315-44ed-b89a-393bd6e4f8bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   x  y\n",
            "0  0  0\n",
            "1  0  1\n",
            "2  0  2\n",
            "3  0  3\n",
            "4  1  0\n"
          ]
        }
      ],
      "source": [
        "# Define the grid dimensions\n",
        "X = 5\n",
        "Y = 4\n",
        "\n",
        "# Create a list of coordinates\n",
        "coords = [(x, y) for x in range(X) for y in range(Y)]\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(coords, columns=['x', 'y'])\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXiiYmmcj5Js"
      },
      "source": [
        "**52**. For this DataFrame `df`, create a new column of zeros (safe) and ones (mine). The probability of a mine occuring at each location should be 0.4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "nJ0xRMV5j5Js"
      },
      "outputs": [],
      "source": [
        "# Create a new column 'mine' with random values, with a probability of 0.4 for a mine\n",
        "df['mine'] = np.random.choice([0, 1], size=len(df), p=[0.6, 0.4])\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGhZM9Yoj5Js"
      },
      "source": [
        "**53**. Now create a new column for this DataFrame called `'adjacent'`. This column should contain the number of mines found on adjacent squares in the grid.\n",
        "\n",
        "(E.g. for the first row, which is the entry for the coordinate `(0, 0)`, count how many mines are found on the coordinates `(0, 1)`, `(1, 0)` and `(1, 1)`.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "b-j0Wjpqj5Js"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6zkHvrXj5Jt"
      },
      "source": [
        "**54**. For rows of the DataFrame that contain a mine, set the value in the `'adjacent'` column to NaN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ulamg93Hj5Jt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3lWuMaRj5Jt"
      },
      "source": [
        "**55**. Finally, convert the DataFrame to grid of the adjacent mine counts: columns are the `x` coordinate, rows are the `y` coordinate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "oIC2Eydrj5Jt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4XRUVg4j5Jt"
      },
      "source": [
        "## Plotting\n",
        "\n",
        "### Visualize trends and patterns in data\n",
        "\n",
        "Difficulty: *medium*\n",
        "\n",
        "To really get a good understanding of the data contained in your DataFrame, it is often essential to create plots: if you're lucky, trends and anomalies will jump right out at you. This functionality is baked into pandas and the puzzles below explore some of what's possible with the library.\n",
        "\n",
        "**56.** Pandas is highly integrated with the plotting library matplotlib, and makes plotting DataFrames very user-friendly! Plotting in a notebook environment usually makes use of the following boilerplate:\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "```\n",
        "\n",
        "matplotlib is the plotting library which pandas' plotting functionality is built upon, and it is usually aliased to ```plt```.\n",
        "\n",
        "```%matplotlib inline``` tells the notebook to show plots inline, instead of creating them in a separate window.  \n",
        "\n",
        "```plt.style.use('ggplot')``` is a style theme that most people find agreeable, based upon the styling of R's ggplot package.\n",
        "\n",
        "For starters, make a scatter plot of this random data, but use black X's instead of the default markers.\n",
        "\n",
        "```df = pd.DataFrame({\"xs\":[1,5,2,8,1], \"ys\":[4,2,1,9,6]})```\n",
        "\n",
        "Consult the [documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.plot.html) if you get stuck!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "AUSAW-Tkj5Jt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gm3ki4uqj5Jt"
      },
      "source": [
        "**57.** Columns in your DataFrame can also be used to modify colors and sizes.  Bill has been keeping track of his performance at work over time, as well as how good he was feeling that day, and whether he had a cup of coffee in the morning.  Make a plot which incorporates all four features of this DataFrame.\n",
        "\n",
        "(Hint:  If you're having trouble seeing the plot, try multiplying the Series which you choose to represent size by 10 or more)\n",
        "\n",
        "*The chart doesn't have to be pretty: this isn't a course in data viz!*\n",
        "\n",
        "```\n",
        "df = pd.DataFrame({\"productivity\":[5,2,3,1,4,5,6,7,8,3,4,8,9],\n",
        "                   \"hours_in\"    :[1,9,6,5,3,9,2,9,1,7,4,2,2],\n",
        "                   \"happiness\"   :[2,1,3,2,3,1,2,3,1,2,2,1,3],\n",
        "                   \"caffienated\" :[0,0,1,1,0,0,0,0,1,1,0,1,0]})\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ldaMCZXRj5Ju"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xMXvyMFj5Ju"
      },
      "source": [
        "**58.**  What if we want to plot multiple things?  Pandas allows you to pass in a matplotlib *Axis* object for plots, and plots will also return an Axis object.\n",
        "\n",
        "Make a bar plot of monthly revenue with a line plot of monthly advertising spending (numbers in millions)\n",
        "\n",
        "```\n",
        "df = pd.DataFrame({\"revenue\":[57,68,63,71,72,90,80,62,59,51,47,52],\n",
        "                   \"advertising\":[2.1,1.9,2.7,3.0,3.6,3.2,2.7,2.4,1.8,1.6,1.3,1.9],\n",
        "                   \"month\":range(12)\n",
        "                  })\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-k8gJD8-j5Ju"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWvsRvOEj5Ju"
      },
      "source": [
        "Now we're finally ready to create a candlestick chart, which is a very common tool used to analyze stock price data.  A candlestick chart shows the opening, closing, highest, and lowest price for a stock during a time window.  The color of the \"candle\" (the thick part of the bar) is green if the stock closed above its opening price, or red if below.\n",
        "\n",
        "![Candlestick Example](img/candle.jpg)\n",
        "\n",
        "This was initially designed to be a pandas plotting challenge, but it just so happens that this type of plot is just not feasible using pandas' methods.  If you are unfamiliar with matplotlib, we have provided a function that will plot the chart for you so long as you can use pandas to get the data into the correct format.\n",
        "\n",
        "Your first step should be to get the data in the correct format using pandas' time-series grouping function.  We would like each candle to represent an hour's worth of data.  You can write your own aggregation function which returns the open/high/low/close, but pandas has a built-in which also does this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGea7Hsjj5Ju"
      },
      "source": [
        "The below cell contains helper functions.  Call ```day_stock_data()``` to generate a DataFrame containing the prices a hypothetical stock sold for, and the time the sale occurred.  Call ```plot_candlestick(df)``` on your properly aggregated and formatted stock data to print the candlestick chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HIhMBQPPj5Jv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def float_to_time(x):\n",
        "    return str(int(x)) + \":\" + str(int(x%1 * 60)).zfill(2) + \":\" + str(int(x*60 % 1 * 60)).zfill(2)\n",
        "\n",
        "def day_stock_data():\n",
        "    #NYSE is open from 9:30 to 4:00\n",
        "    time = 9.5\n",
        "    price = 100\n",
        "    results = [(float_to_time(time), price)]\n",
        "    while time < 16:\n",
        "        elapsed = np.random.exponential(.001)\n",
        "        time += elapsed\n",
        "        if time > 16:\n",
        "            break\n",
        "        price_diff = np.random.uniform(.999, 1.001)\n",
        "        price *= price_diff\n",
        "        results.append((float_to_time(time), price))\n",
        "\n",
        "\n",
        "    df = pd.DataFrame(results, columns = ['time','price'])\n",
        "    df.time = pd.to_datetime(df.time)\n",
        "    return df\n",
        "\n",
        "#Don't read me unless you get stuck!\n",
        "def plot_candlestick(agg):\n",
        "    \"\"\"\n",
        "    agg is a DataFrame which has a DatetimeIndex and five columns: [\"open\",\"high\",\"low\",\"close\",\"color\"]\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots()\n",
        "    for time in agg.index:\n",
        "        ax.plot([time.hour] * 2, agg.loc[time, [\"high\",\"low\"]].values, color = \"black\")\n",
        "        ax.plot([time.hour] * 2, agg.loc[time, [\"open\",\"close\"]].values, color = agg.loc[time, \"color\"], linewidth = 10)\n",
        "\n",
        "    ax.set_xlim((8,16))\n",
        "    ax.set_ylabel(\"Price\")\n",
        "    ax.set_xlabel(\"Hour\")\n",
        "    ax.set_title(\"OHLC of Stock Value During Trading Day\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCZI5MrFj5Jv"
      },
      "source": [
        "**59.** Generate a day's worth of random stock data, and aggregate / reformat it so that it has hourly summaries of the opening, highest, lowest, and closing prices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "1I2MBmyVj5Jw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r33btb_Fj5Jw"
      },
      "source": [
        "**60.** Now that you have your properly-formatted data, try to plot it yourself as a candlestick chart.  Use the ```plot_candlestick(df)``` function above, or matplotlib's [```plot``` documentation](https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.plot.html) if you get stuck."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ZXk3q6yhj5Jw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVscXgb0j5Jw"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}